{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5818ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d116fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH_SPO2_LOW = 92\n",
    "THRESH_SPO2_CRITICAL = 88\n",
    "THRESH_SHOCK_INDEX_WARNING = 0.9\n",
    "THRESH_SHOCK_INDEX_CRITICAL = 1.0\n",
    "THRESH_MAP_LOW = 65  # Mean Arterial Pressure threshold for shock\n",
    "THRESH_LACTATE_HIGH = 2.0  # mmol/L for tissue hypoperfusion\n",
    "THRESH_LACTATE_CRITICAL = 4.0\n",
    "THRESH_UO_LOW = 0.5  # mL/kg/hr (oliguria)\n",
    "\n",
    "# Trend Analysis\n",
    "TREND_WINDOW = 6  # Number of readings for short-term trend analysis\n",
    "\n",
    "# AGE_THRESHOLDS (kept same as user-provided)\n",
    "AGE_THRESHOLDS = {\n",
    "    'neonate': {\n",
    "        'rr_low': 30, 'rr_normal': 40, 'rr_high': 60,\n",
    "        'hr_low': 100, 'hr_normal': 140, 'hr_high': 160,\n",
    "        'sbp_low': 60, 'sbp_normal': 70, 'sbp_high': 90,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.2, 'temp_high': 38.0\n",
    "    },\n",
    "    'infant': {\n",
    "        'rr_low': 24, 'rr_normal': 30, 'rr_high': 40,\n",
    "        'hr_low': 80, 'hr_normal': 120, 'hr_high': 140,\n",
    "        'sbp_low': 70, 'sbp_normal': 85, 'sbp_high': 100,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.2, 'temp_high': 38.0\n",
    "    },\n",
    "    'child': {\n",
    "        'rr_low': 16, 'rr_normal': 20, 'rr_high': 30,\n",
    "        'hr_low': 70, 'hr_normal': 90, 'hr_high': 110,\n",
    "        'sbp_low': 80, 'sbp_normal': 95, 'sbp_high': 110,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.0, 'temp_high': 38.0\n",
    "    },\n",
    "    'adolescent': {\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 20,\n",
    "        'hr_low': 60, 'hr_normal': 75, 'hr_high': 100,\n",
    "        'sbp_low': 90, 'sbp_normal': 105, 'sbp_high': 120,\n",
    "        'temp_low': 35.8, 'temp_normal': 36.8, 'temp_high': 37.8\n",
    "    },\n",
    "    'adult': {\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 20,\n",
    "        'hr_low': 60, 'hr_normal': 80, 'hr_high': 100,\n",
    "        'sbp_low': 90, 'sbp_normal': 115, 'sbp_high': 130,\n",
    "        'temp_low': 35.5, 'temp_normal': 36.8, 'temp_high': 38.0\n",
    "    },\n",
    "    'geriatric': {\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 24,\n",
    "        'hr_low': 55, 'hr_normal': 70, 'hr_high': 90,\n",
    "        'sbp_low': 90, 'sbp_normal': 125, 'sbp_high': 140,\n",
    "        'temp_low': 35.5, 'temp_normal': 36.5, 'temp_high': 37.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e897eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_age_category(df):\n",
    "    df = df.copy()\n",
    "    def _categorize(age):\n",
    "        if age <= 0.083: return 'neonate'\n",
    "        elif age <= 1:   return 'infant'\n",
    "        elif age < 5:    return 'child'\n",
    "        elif age < 13:   return 'adolescent'\n",
    "        elif age < 65:   return 'adult'\n",
    "        else:            return 'geriatric'\n",
    "    if 'age' in df.columns:\n",
    "        df['age_category'] = df['age'].apply(_categorize)\n",
    "    else:\n",
    "        df['age_category'] = 'adult'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e37a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vital_range_flags(df):\n",
    "    df = df.copy()\n",
    "    df = assign_age_category(df)\n",
    "\n",
    "    # SpO₂ flags\n",
    "    df['flag_spo2_low'] = df['spo2'] < THRESH_SPO2_LOW\n",
    "    df['flag_spo2_critical'] = df['spo2'] < THRESH_SPO2_CRITICAL\n",
    "\n",
    "    # Temperature flags\n",
    "    df['flag_temp_high'] = df.apply(lambda row: row['temperature'] >= AGE_THRESHOLDS[row['age_category']]['temp_high'], axis=1)\n",
    "    df['flag_temp_low'] = df.apply(lambda row: row['temperature'] < AGE_THRESHOLDS[row['age_category']]['temp_low'], axis=1)\n",
    "\n",
    "    # Respiratory Rate flags\n",
    "    df['flag_rr_low'] = df.apply(lambda row: row['resp_rate'] < AGE_THRESHOLDS[row['age_category']]['rr_low'], axis=1)\n",
    "    df['flag_rr_high'] = df.apply(lambda row: row['resp_rate'] >= AGE_THRESHOLDS[row['age_category']]['rr_high'], axis=1)\n",
    "\n",
    "    # Heart Rate flags\n",
    "    df['flag_hr_low'] = df.apply(lambda row: row['heart_rate'] < AGE_THRESHOLDS[row['age_category']]['hr_low'], axis=1)\n",
    "    df['flag_hr_high'] = df.apply(lambda row: row['heart_rate'] >= AGE_THRESHOLDS[row['age_category']]['hr_high'], axis=1)\n",
    "\n",
    "    # Shock Index\n",
    "    df['shock_index'] = df['heart_rate'] / np.clip(df['sbp'], a_min=1, a_max=None)\n",
    "    df['flag_si_warning'] = df['shock_index'] >= THRESH_SHOCK_INDEX_WARNING\n",
    "    df['flag_si_critical'] = df['shock_index'] >= THRESH_SHOCK_INDEX_CRITICAL\n",
    "\n",
    "    # Blood Pressure flags (sbp/dbp)\n",
    "    df['flag_sbp_low'] = df.apply(lambda row: row['sbp'] < AGE_THRESHOLDS[row['age_category']]['sbp_low'], axis=1)\n",
    "    df['flag_sbp_high'] = df.apply(lambda row: row['sbp'] >= AGE_THRESHOLDS[row['age_category']]['sbp_high'], axis=1)\n",
    "    df['flag_dbp_low'] = df.apply(lambda row: row['dbp'] < (AGE_THRESHOLDS[row['age_category']]['sbp_low'] * 0.6), axis=1)\n",
    "    df['flag_dbp_high'] = df.apply(lambda row: row['dbp'] >= (AGE_THRESHOLDS[row['age_category']]['sbp_high'] * 0.6), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00939ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recent_trends_delta(df):\n",
    "    \"\"\"\n",
    "    Computes recent trends for each vital by differencing consecutive readings.\n",
    "    Uses age-specific thresholds + detects likely false-positive variations\n",
    "    (e.g., transient spikes/drops or conflicting multi-vital patterns).\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    if 'age_category' not in df.columns:\n",
    "        df = assign_age_category(df)\n",
    "\n",
    "    trends = {}\n",
    "    recent = df.tail(TREND_WINDOW)\n",
    "    if recent.empty:\n",
    "        return trends\n",
    "\n",
    "    age_group = recent['age_category'].iloc[-1]\n",
    "    thresholds = AGE_THRESHOLDS[age_group]\n",
    "\n",
    "    vital_map = {\n",
    "        'rr': ('rr_low', 'rr_normal', 'rr_high'),\n",
    "        'hr': ('hr_low', 'hr_normal', 'hr_high'), \n",
    "        'sbp': ('sbp_low', 'sbp_normal', 'sbp_high'),\n",
    "        'temperature': ('temp_low', 'temp_normal', 'temp_high'),\n",
    "        'spo2': (None, None, None)\n",
    "    }\n",
    "\n",
    "    # --- Enhanced false positive detection ---\n",
    "    def is_transient_spike(values, delta, threshold_ratio=0.15):\n",
    "        \"\"\"Detect short-lived sharp deviations likely due to artifacts.\"\"\"\n",
    "        if len(values) < 3 or np.isnan(values).any():\n",
    "            return False\n",
    "        median_val = np.median(values)\n",
    "        if median_val == 0:\n",
    "            return False\n",
    "        deviation = abs(values[-1] - median_val)\n",
    "        return deviation / median_val > threshold_ratio and abs(delta) < 0.2 * deviation\n",
    "\n",
    "    def is_unstable_signal(values, threshold_ratio=0.5):\n",
    "        \"\"\"Detect excessive variability suggesting measurement noise.\"\"\"\n",
    "        if len(values) < 2 or np.isnan(values).any():\n",
    "            return False\n",
    "        value_std = np.std(values)\n",
    "        if value_std == 0:\n",
    "            return False\n",
    "        diff_std = np.std(np.diff(values))\n",
    "        return diff_std > threshold_ratio * value_std\n",
    "\n",
    "    for vital in ['rr', 'hr', 'sbp', 'temperature', 'spo2']:\n",
    "        if vital not in recent.columns or recent[vital].isnull().all():\n",
    "            continue\n",
    "\n",
    "        y = recent[vital].dropna().values\n",
    "        if len(y) < 2:\n",
    "            continue\n",
    "\n",
    "        avg_delta = np.mean(np.diff(y))\n",
    "        latest = y[-1]\n",
    "        trends[f\"{vital}_trend\"] = round(avg_delta, 3)\n",
    "\n",
    "        # --- Enhanced false positive detection ---\n",
    "        transient_spike = is_transient_spike(y, avg_delta)\n",
    "        unstable_signal = is_unstable_signal(y)\n",
    "        \n",
    "        fp_evidence = []\n",
    "        if transient_spike:\n",
    "            fp_evidence.append(\"transient_spike\")\n",
    "        if unstable_signal:\n",
    "            fp_evidence.append(\"unstable_signal\")\n",
    "\n",
    "        # SPO₂ special handling\n",
    "        if vital == 'spo2':\n",
    "            if latest < THRESH_SPO2_LOW:\n",
    "                if avg_delta > 0:\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                elif avg_delta < 0:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and flat\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        else:\n",
    "            low_key, norm_key, high_key = vital_map[vital]\n",
    "            low = thresholds[low_key]\n",
    "            normal = thresholds[norm_key]  \n",
    "            high = thresholds[high_key]\n",
    "\n",
    "            if latest < low or latest > high:\n",
    "                if (latest > high and avg_delta < 0) or (latest < low and avg_delta > 0):\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        if fp_evidence:\n",
    "            flag += f\" (possible false-positive: {', '.join(fp_evidence)})\"\n",
    "            trends[f\"{vital}_false_positive\"] = True\n",
    "            trends[f\"{vital}_fp_evidence\"] = fp_evidence\n",
    "            trends[f\"{vital}_confidence\"] = \"LOW\"\n",
    "        else:\n",
    "            trends[f\"{vital}_false_positive\"] = False\n",
    "            trends[f\"{vital}_confidence\"] = \"HIGH\"\n",
    "\n",
    "        trends[f\"{vital}_trend_flag\"] = flag\n",
    "\n",
    "    # --- Shock Index trend ---\n",
    "    if all(col in recent.columns for col in ['hr', 'sbp']):\n",
    "        hr = recent['hr'].values\n",
    "        sbp = np.clip(recent['sbp'].values, a_min=1, a_max=None)\n",
    "        si = hr / sbp\n",
    "\n",
    "        if len(si) >= 2:\n",
    "            avg_si_delta = np.mean(np.diff(si))\n",
    "            trends['shock_index_trend'] = round(avg_si_delta, 3)\n",
    "\n",
    "            latest_si = si[-1]\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_CRITICAL:\n",
    "                flag = \"Shock Index high — improving\" if avg_si_delta < 0 else \"Shock Index high — worsening\"\n",
    "            else:\n",
    "                flag = \"Normal but improving\" if avg_si_delta < 0 else \"Normal but rising\"\n",
    "\n",
    "            si_fp_evidence = []\n",
    "            if is_unstable_signal(si, threshold_ratio=0.3):\n",
    "                si_fp_evidence.append(\"unstable_si\")\n",
    "\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_CRITICAL:\n",
    "                latest_hr = recent['hr'].iloc[-1]\n",
    "                latest_sbp = recent['sbp'].iloc[-1]\n",
    "                hr_normal = latest_hr < thresholds['hr_high']\n",
    "                sbp_normal = latest_sbp >= thresholds['sbp_low']\n",
    "                \n",
    "                if (hr_normal and not sbp_normal) or (sbp_normal and not hr_normal):\n",
    "                    si_fp_evidence.append(\"single_component_abnormality\")\n",
    "\n",
    "            if si_fp_evidence:\n",
    "                flag += f\" (possible false-positive: {', '.join(si_fp_evidence)})\"\n",
    "                trends['shock_index_false_positive'] = True\n",
    "                trends['shock_index_fp_evidence'] = si_fp_evidence\n",
    "                trends['shock_index_confidence'] = \"LOW\"\n",
    "            else:\n",
    "                trends['shock_index_false_positive'] = False  \n",
    "                trends['shock_index_confidence'] = \"HIGH\"\n",
    "\n",
    "            trends['shock_index_trend_flag'] = flag\n",
    "\n",
    "    # --- Overall confidence summary ---\n",
    "    false_positive_count = sum(1 for key in trends if key.endswith('_false_positive') and trends[key])\n",
    "    total_metrics = sum(1 for key in trends if key.endswith('_false_positive'))\n",
    "    \n",
    "    if total_metrics > 0:\n",
    "        fp_ratio = false_positive_count / total_metrics\n",
    "        if fp_ratio >= 0.5:\n",
    "            trends['overall_confidence'] = \"LOW\"\n",
    "        elif fp_ratio >= 0.25:\n",
    "            trends['overall_confidence'] = \"MEDIUM\" \n",
    "        else:\n",
    "            trends['overall_confidence'] = \"HIGH\"\n",
    "    else:\n",
    "        trends['overall_confidence'] = \"HIGH\"\n",
    "\n",
    "    return trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184ff861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_odi(nightly_spo2_df):\n",
    "    \"\"\"\n",
    "    Processes a DataFrame of nocturnal SpO2 readings to calculate the Oxygen Desaturation Index (ODI).\n",
    "    The DataFrame must have 'timestamp' and 'spo2' columns.\n",
    "\n",
    "    Args:\n",
    "        nightly_spo2_df (pd.DataFrame): DataFrame containing SpO2 data for a single night.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing ODI, event count, valid hours, and the list of events.\n",
    "    \"\"\"\n",
    "    # SLEEP APNEA SPECIFIC THRESHOLDS for event detection\n",
    "    EVENT_DROP_PERCENT = 3\n",
    "    EVENT_RECOVERY_PERCENT = 1.5\n",
    "    MIN_EVENT_DURATION = 10\n",
    "\n",
    "    if nightly_spo2_df.empty or len(nightly_spo2_df) < 2:\n",
    "        return {'odi': 0, 'event_count': 0, 'valid_hours': 0, 'events': []}\n",
    "\n",
    "    df = nightly_spo2_df.sort_values('timestamp').reset_index(drop=True).copy()\n",
    "    df['time_diff'] = df['timestamp'].diff().dt.total_seconds().fillna(0)\n",
    "    total_duration_seconds = (df['timestamp'].iloc[-1] - df['timestamp'].iloc[0]).total_seconds()\n",
    "    valid_hours = total_duration_seconds / 3600\n",
    "\n",
    "    events = []\n",
    "    in_event = False\n",
    "    event_start_index = None\n",
    "    baseline_spo2 = None\n",
    "\n",
    "    for i in range(1, len(df)):\n",
    "        current_spo2 = df['spo2'].iloc[i]\n",
    "        prev_spo2 = df['spo2'].iloc[i-1]\n",
    "\n",
    "        if not in_event:\n",
    "            # Look for the start of an event: a drop of >= EVENT_DROP_PERCENT\n",
    "            if prev_spo2 - current_spo2 >= EVENT_DROP_PERCENT:\n",
    "                in_event = True\n",
    "                event_start_index = i-1\n",
    "                baseline_spo2 = df['spo2'].iloc[event_start_index]\n",
    "        else:\n",
    "            # We are in an event. Look for recovery: a rise of >= EVENT_RECOVERY_PERCENT from the nadir\n",
    "            current_nadir = df['spo2'].iloc[event_start_index:i+1].min()\n",
    "            if current_spo2 - current_nadir >= EVENT_RECOVERY_PERCENT:\n",
    "                # Event has ended\n",
    "                event_end_index = i\n",
    "                event_duration = (df['timestamp'].iloc[event_end_index] - df['timestamp'].iloc[event_start_index]).total_seconds()\n",
    "                \n",
    "                if event_duration >= MIN_EVENT_DURATION:\n",
    "                    # Record the event\n",
    "                    nadir_value = current_nadir\n",
    "                    drop_from_baseline = baseline_spo2 - nadir_value\n",
    "                    events.append({\n",
    "                        'start': df['timestamp'].iloc[event_start_index],\n",
    "                        'end': df['timestamp'].iloc[event_end_index],\n",
    "                        'nadir_spo2': nadir_value,\n",
    "                        'drop_amount': drop_from_baseline\n",
    "                    })\n",
    "                # Reset for next event\n",
    "                in_event = False\n",
    "                event_start_index = None\n",
    "                baseline_spo2 = None\n",
    "\n",
    "    # Handle case where an event is still ongoing at the end of the data\n",
    "    if in_event:\n",
    "        event_duration = (df['timestamp'].iloc[-1] - df['timestamp'].iloc[event_start_index]).total_seconds()\n",
    "        if event_duration >= MIN_EVENT_DURATION:\n",
    "            nadir_value = df['spo2'].iloc[event_start_index:].min()\n",
    "            drop_from_baseline = baseline_spo2 - nadir_value\n",
    "            events.append({\n",
    "                'start': df['timestamp'].iloc[event_start_index],\n",
    "                'end': df['timestamp'].iloc[-1],\n",
    "                'nadir_spo2': nadir_value,\n",
    "                'drop_amount': drop_from_baseline\n",
    "            })\n",
    "\n",
    "    event_count = len(events)\n",
    "    odi = event_count / valid_hours if valid_hours > 0 else 0\n",
    "\n",
    "    return {'odi': odi, 'event_count': event_count, 'valid_hours': valid_hours, 'events': events}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36429de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sleep_apnea(df, window_hours=24):\n",
    "    \"\"\"\n",
    "    Detect Sleep Apnea Concern using nocturnal SpO₂ and HR variability.\n",
    "    Now integrates trend analysis for false positive reduction.\n",
    "\n",
    "    Parameters:\n",
    "        df: DataFrame with ['timestamp','spo2','heart_rate','age'] at minimum\n",
    "        window_hours: rolling window for analysis (default: last 24h)\n",
    "\n",
    "    Returns:\n",
    "        dict with concern level, reasons, and features\n",
    "    \"\"\"\n",
    "    # --- DATA PREPARATION --- \n",
    "    df = df.copy().sort_values(\"timestamp\")\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "    # Use last 24h data\n",
    "    cutoff = df['timestamp'].max() - timedelta(hours=window_hours)\n",
    "    df_24h = df[df['timestamp'] >= cutoff]\n",
    "\n",
    "    # Apply your standard flags FIRST (reusing your function)\n",
    "    df_24h = apply_vital_range_flags(df_24h) \n",
    "\n",
    "    # Isolate nocturnal data\n",
    "    nocturnal_mask = df_24h['hour'].between(0, 6)\n",
    "    nocturnal_data = df_24h[nocturnal_mask].copy()\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # --- FEATURE CALCULATION ---\n",
    "    # 1. Reuse your existing Nocturnal Drop feature\n",
    "    night_spo2 = nocturnal_data['spo2'].dropna()\n",
    "    day_spo2   = df_24h[df_24h['hour'].between(8, 20)]['spo2'].dropna()\n",
    "    if not night_spo2.empty and not day_spo2.empty:\n",
    "        features['nocturnal_drop'] = round(night_spo2.median() - day_spo2.median(), 2)\n",
    "    else:\n",
    "        features['nocturnal_drop'] = np.nan\n",
    "\n",
    "    # 2. Calculate TRUE ODI and events\n",
    "    odi_results = calculate_odi(nocturnal_data[['timestamp', 'spo2']])\n",
    "    features['odi'] = round(odi_results['odi'], 2)\n",
    "    features['desat_events'] = odi_results['event_count']\n",
    "    features['valid_nocturnal_hours'] = round(odi_results['valid_hours'], 2)\n",
    "\n",
    "    # 3. Calculate % time low (REUSING existing flags!)\n",
    "    total_nocturnal_readings = len(nocturnal_data)\n",
    "    if total_nocturnal_readings > 0:\n",
    "        features['percent_time_below_90'] = (nocturnal_data['flag_spo2_low'].sum() / total_nocturnal_readings) * 100\n",
    "        features['percent_time_below_88'] = (nocturnal_data['flag_spo2_critical'].sum() / total_nocturnal_readings) * 100\n",
    "    else:\n",
    "        features['percent_time_below_90'] = 0\n",
    "        features['percent_time_below_88'] = 0\n",
    "\n",
    "    # 4. Heart Rate Variability\n",
    "    nocturnal_hr = nocturnal_data['heart_rate'].dropna()\n",
    "    if not nocturnal_hr.empty:\n",
    "        features['hr_sd'] = round(nocturnal_hr.std(), 2)\n",
    "        features['hr_brady_episodes'] = int((nocturnal_hr < 60).sum())\n",
    "        features['hr_tachy_episodes'] = int((nocturnal_hr > 100).sum())\n",
    "    else:\n",
    "        features['hr_sd'] = np.nan\n",
    "        features['hr_brady_episodes'] = 0\n",
    "        features['hr_tachy_episodes'] = 0\n",
    "\n",
    "    # --- TREND ANALYSIS ON NOCTURNAL DATA FOR FALSE POSITIVE REDUCTION ---\n",
    "    trends = compute_recent_trends_delta(nocturnal_data)  # Analyze nocturnal trends only\n",
    "    \n",
    "    # Get trend context for false positive reduction\n",
    "    spo2_trend_flag = trends.get('spo2_trend_flag', 'Normal and stable')\n",
    "    spo2_trend_value = trends.get('spo2_trend', 0)\n",
    "    \n",
    "    # FALSE POSITIVE FILTERS\n",
    "    is_improving_rapidly = spo2_trend_flag == \"Still abnormal — but improving\" and spo2_trend_value > 0.5\n",
    "    is_transient_dip = spo2_trend_flag == \"Normal but deteriorating\" and features['odi'] < 2.0\n",
    "    is_very_mild_and_stable = features['odi'] < 1.0 and spo2_trend_flag == \"Normal and stable\"\n",
    "\n",
    "    # --- CLASSIFICATION LOGIC WITH FALSE POSITIVE REDUCTION ---\n",
    "    reasons = []\n",
    "    concern = \"green\"\n",
    "\n",
    "    # PRIMARY RULE: Based on true ODI and prolonged hypoxemia\n",
    "    if (features['odi'] >= 5.0 or features['percent_time_below_88'] > 5) and not is_improving_rapidly:\n",
    "        concern = \"red\"\n",
    "        reasons.append(f\"Oxygen Desaturation Index (ODI) ≥5.0 ({features['odi']}/hr) or significant time with SpO₂ <88%\")\n",
    "    \n",
    "    # SECONDARY RULE: Based on lower ODI or less severe hypoxemia\n",
    "    elif (features['odi'] >= 3.0 or features['percent_time_below_90'] > 10) and not is_transient_dip:\n",
    "        concern = \"orange\"\n",
    "        reasons.append(f\"Moderate ODI ({features['odi']}/hr) or prolonged time with SpO₂ <90%\")\n",
    "    \n",
    "    # TERTIARY RULE: Mild indicators (skip very mild stable patterns)\n",
    "    elif (features['odi'] > 0 or (features['nocturnal_drop'] is not np.nan and features['nocturnal_drop'] <= -2)) and not is_very_mild_and_stable:\n",
    "        concern = \"yellow\"\n",
    "        reasons.append(\"Mild nocturnal desaturation detected\")\n",
    "\n",
    "    # MODIFIER RULE: HR Variability can upgrade concern\n",
    "    if features['hr_sd'] > 8.0 and concern != \"red\": \n",
    "        if concern == \"green\":  # FIXED: was mismatched quote\n",
    "            concern = \"yellow\"\n",
    "            reasons.append(\"Elevated nocturnal heart rate variability.\")\n",
    "        elif concern == \"yellow\":\n",
    "            concern = \"orange\"\n",
    "            reasons.append(\"Elevated nocturnal heart rate variability plus desaturation.\")\n",
    "\n",
    "    # Add trend context to reasons if it influenced the decision\n",
    "    if is_improving_rapidly and (features['odi'] >= 5.0 or features['percent_time_below_88'] > 5):\n",
    "        reasons.append(\"Note: Pattern shows improving trend despite current severity\")\n",
    "    elif is_transient_dip and (features['odi'] >= 3.0 or features['percent_time_below_90'] > 10):\n",
    "        reasons.append(\"Note: Appears to be transient dip based on trend analysis\")\n",
    "    elif is_very_mild_and_stable:\n",
    "        reasons.append(\"Note: Very mild pattern with stable trend\")\n",
    "\n",
    "    # Include trend info in features for transparency\n",
    "    features['trend_context'] = {\n",
    "        'spo2_trend_flag': spo2_trend_flag,\n",
    "        'spo2_trend_value': spo2_trend_value,\n",
    "        'heart_rate_trend_flag': trends.get('heart_rate_trend_flag', 'Not available'),\n",
    "        'resp_rate_trend_flag': trends.get('resp_rate_trend_flag', 'Not available')\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"concern\": concern,\n",
    "        \"features\": features,\n",
    "        \"reasons\": reasons\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3efb51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sleep apnea detection on sample data...\n",
      "\n",
      "Overall Concern Level: ORANGE\n",
      "Reasons:\n",
      "  - Moderate ODI (0.83/hr) or prolonged time with SpO₂ <90%\n",
      "\n",
      "Calculated Features:\n",
      "  - nocturnal_drop: nan\n",
      "  - odi: 0.83\n",
      "  - desat_events: 5\n",
      "  - valid_nocturnal_hours: 6.0\n",
      "  - percent_time_below_90: 19.667590027700832\n",
      "  - percent_time_below_88: 2.21606648199446\n",
      "  - hr_sd: 5.12\n",
      "  - hr_brady_episodes: 0\n",
      "  - hr_tachy_episodes: 0\n",
      "  - trend_context: {'spo2_trend_flag': 'Normal and stable (possible false-positive: unstable_signal)', 'spo2_trend_value': np.float64(0.152), 'heart_rate_trend_flag': 'Not available', 'resp_rate_trend_flag': 'Not available'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a timestamp range for 6 hours at 1-minute intervals (00:00 to 06:00)\n",
    "timestamps = pd.date_range(start=\"2024-01-01 00:00\", end=\"2024-01-01 06:00\", freq='1min')\n",
    "\n",
    "# Create a baseline SpO2 value\n",
    "baseline_spo2 = 97\n",
    "spo2_values = np.full(len(timestamps), baseline_spo2)\n",
    "\n",
    "# --- Simulate 3 CLEAR Desaturation Events ---\n",
    "# Event 1: A deep, long event (typical of apnea)\n",
    "event_1_start = 60  # After 1 hour (01:00 AM)\n",
    "spo2_values[event_1_start:event_1_start+20] = 92  # Drop to 92\n",
    "spo2_values[event_1_start+20:event_1_start+25] = 88  # Nadir at 88\n",
    "spo2_values[event_1_start+25:event_1_start+45] = 92  # Slow recovery\n",
    "# spo2 returns to baseline after event_1_start+45\n",
    "\n",
    "# Event 2: A shorter, shallower event\n",
    "event_2_start = 180  # After 3 hours (03:00 AM)\n",
    "spo2_values[event_2_start:event_2_start+15] = 93  # Drop to 93\n",
    "spo2_values[event_2_start+15:event_2_start+20] = 90  # Nadir at 90\n",
    "spo2_values[event_2_start+20:event_2_start+35] = 93  # Recovery\n",
    "# spo2 returns to baseline after event_2_start+35\n",
    "\n",
    "# Event 3: Another clear event\n",
    "event_3_start = 270  # After 4.5 hours (04:30 AM)\n",
    "spo2_values[event_3_start:event_3_start+15] = 91\n",
    "spo2_values[event_3_start+15:event_3_start+20] = 87  # Nadir < 88\n",
    "spo2_values[event_3_start+20:event_3_start+40] = 91\n",
    "\n",
    "# Add some small random noise to make it look more realistic, but keep the events clear\n",
    "np.random.seed(42) # For reproducible results\n",
    "spo2_values = spo2_values + np.random.normal(0, 0.5, len(spo2_values))\n",
    "spo2_values = np.clip(spo2_values, 80, 100) # Ensure values stay within possible range\n",
    "\n",
    "# --- Create the Test DataFrame ---\n",
    "df_test = pd.DataFrame({\n",
    "    'timestamp': timestamps,\n",
    "    'spo2': spo2_values,\n",
    "    'heart_rate': np.random.normal(75, 5, len(timestamps)), # Random HR around 75\n",
    "    'resp_rate': np.random.normal(16, 2, len(timestamps)),  # Random RR around 16\n",
    "    'age': 45, # Set an age\n",
    "    # Add other columns your pipeline might expect, even if with dummy data\n",
    "    'sbp': 120,\n",
    "    'dbp': 80,\n",
    "    'temperature': 36.8\n",
    "})\n",
    "\n",
    "# --- RUN THE TEST ---\n",
    "print(\"Running sleep apnea detection on sample data...\")\n",
    "result = detect_sleep_apnea(df_test, window_hours=24)\n",
    "\n",
    "# --- PRINT THE RESULTS ---\n",
    "print(f\"\\nOverall Concern Level: {result['concern'].upper()}\")\n",
    "print(\"Reasons:\")\n",
    "for reason in result['reasons']:\n",
    "    print(f\"  - {reason}\")\n",
    "print(\"\\nCalculated Features:\")\n",
    "for key, value in result['features'].items():\n",
    "    print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee21d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recent_trends_delta(df, trend_window=TREND_WINDOW):\n",
    "    df = df.copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    if 'age_category' not in df.columns:\n",
    "        df = assign_age_category(df)\n",
    "    trends = {}\n",
    "    recent = df.tail(trend_window)\n",
    "    if recent.empty:\n",
    "        return trends\n",
    "    age_group = recent['age_category'].iloc[-1]\n",
    "    thresholds = AGE_THRESHOLDS[age_group]\n",
    "\n",
    "    vital_map = {\n",
    "        'resp_rate': ('rr_low', 'rr_normal', 'rr_high'),\n",
    "        'heart_rate': ('hr_low', 'hr_normal', 'hr_high'),\n",
    "        'sbp': ('sbp_low', 'sbp_normal', 'sbp_high'),\n",
    "        'temperature': ('temp_low', 'temp_normal', 'temp_high'),\n",
    "        'spo2': (None, None, None)\n",
    "    }\n",
    "\n",
    "    for vital in ['resp_rate', 'heart_rate', 'sbp', 'temperature', 'spo2']:\n",
    "        if vital not in recent.columns or recent[vital].isnull().all():\n",
    "            continue\n",
    "        y = recent[vital].dropna().values\n",
    "        if len(y) < 2:\n",
    "            continue\n",
    "        avg_delta = np.mean(np.diff(y))\n",
    "        latest = y[-1]\n",
    "        trends[f\"{vital}_trend\"] = round(avg_delta, 3)\n",
    "\n",
    "        if vital == 'spo2':\n",
    "            if latest < THRESH_SPO2_LOW:\n",
    "                if avg_delta > 0:\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                elif avg_delta < 0:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and flat\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "        else:\n",
    "            low_key, norm_key, high_key = vital_map[vital]\n",
    "            low = thresholds[low_key]\n",
    "            normal = thresholds[norm_key]\n",
    "            high = thresholds[high_key]\n",
    "            if latest < low or latest > high:\n",
    "                if (latest > high and avg_delta < 0) or (latest < low and avg_delta > 0):\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "        trends[f\"{vital}_trend_flag\"] = flag\n",
    "\n",
    "    # Shock Index trend\n",
    "    if all(col in recent.columns for col in ['heart_rate', 'sbp']):\n",
    "        hr = recent['heart_rate'].values\n",
    "        sbp = np.clip(recent['sbp'].values, a_min=1, a_max=None)\n",
    "        si = hr / sbp\n",
    "        if len(si) >= 2:\n",
    "            avg_si_delta = np.mean(np.diff(si))\n",
    "            trends['shock_index_trend'] = round(avg_si_delta, 3)\n",
    "            latest_si = si[-1]\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_CRITICAL:\n",
    "                flag = \"Shock Index critical — improving\" if avg_si_delta < 0 else \"Shock Index critical — worsening\"\n",
    "            else:\n",
    "                flag = \"Normal but improving\" if avg_si_delta < 0 else \"Normal but rising\"\n",
    "            trends['shock_index_trend_flag'] = flag\n",
    "    return trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cc4afd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_sleep_apnea(df, window_hours=24):\n",
    "    \"\"\"\n",
    "    Detect Sleep Apnea Concern using nocturnal SpO₂ and HR variability.\n",
    "    Now integrates with existing pipeline functions for robust event detection.\n",
    "\n",
    "    Parameters:\n",
    "        df: DataFrame with ['timestamp','spo2','heart_rate','age'] at minimum\n",
    "        window_hours: rolling window for analysis (default: last 24h)\n",
    "\n",
    "    Returns:\n",
    "        dict with concern level, reasons, and features\n",
    "    \"\"\"\n",
    "    # --- DATA PREPARATION --- \n",
    "    # Reuse your existing data prep pattern\n",
    "    df = df.copy().sort_values(\"timestamp\")\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "\n",
    "    # Use last 24h data\n",
    "    cutoff = df['timestamp'].max() - timedelta(hours=window_hours)\n",
    "    df_24h = df[df['timestamp'] >= cutoff]\n",
    "\n",
    "    # Apply your standard flags FIRST (reusing your function)\n",
    "    # This adds 'flag_spo2_low', 'flag_spo2_critical', etc.\n",
    "    df_24h = apply_vital_range_flags(df_24h) \n",
    "\n",
    "    # Isolate nocturnal data\n",
    "    nocturnal_mask = df_24h['hour'].between(0, 6)\n",
    "    nocturnal_data = df_24h[nocturnal_mask].copy()\n",
    "    \n",
    "    features = {}\n",
    "\n",
    "    # --- FEATURE CALCULATION ---\n",
    "    # 1. Reuse your existing Nocturnal Drop feature\n",
    "    night_spo2 = nocturnal_data['spo2'].dropna()\n",
    "    day_spo2   = df_24h[df_24h['hour'].between(8, 20)]['spo2'].dropna()\n",
    "    if not night_spo2.empty and not day_spo2.empty:\n",
    "        features['nocturnal_drop'] = round(night_spo2.median() - day_spo2.median(), 2)\n",
    "    else:\n",
    "        features['nocturnal_drop'] = np.nan\n",
    "\n",
    "    # 2. NEW & IMPROVED: Calculate TRUE ODI and events\n",
    "    odi_results = calculate_odi(nocturnal_data[['timestamp', 'spo2']])\n",
    "    features['odi'] = round(odi_results['odi'], 2)\n",
    "    features['desat_events'] = odi_results['event_count'] # Renamed to reflect it's true \"events\"\n",
    "    features['valid_nocturnal_hours'] = round(odi_results['valid_hours'], 2)\n",
    "\n",
    "    # 3. IMPROVED: Calculate % time low (REUSING existing flags!)\n",
    "    total_nocturnal_readings = len(nocturnal_data)\n",
    "    if total_nocturnal_readings > 0:\n",
    "        features['percent_time_below_90'] = (nocturnal_data['flag_spo2_low'].sum() / total_nocturnal_readings) * 100\n",
    "        features['percent_time_below_88'] = (nocturnal_data['flag_spo2_critical'].sum() / total_nocturnal_readings) * 100\n",
    "    else:\n",
    "        features['percent_time_below_90'] = 0\n",
    "        features['percent_time_below_88'] = 0\n",
    "\n",
    "    # 4. IMPROVED: Heart Rate Variability (Standard Deviation)\n",
    "    nocturnal_hr = nocturnal_data['heart_rate'].dropna()\n",
    "    if not nocturnal_hr.empty:\n",
    "        features['hr_sd'] = round(nocturnal_hr.std(), 2) # Key metric for variability\n",
    "        features['hr_brady_episodes'] = int((nocturnal_hr < 60).sum()) # Keep as context\n",
    "        features['hr_tachy_episodes'] = int((nocturnal_hr > 100).sum()) # Keep as context\n",
    "    else:\n",
    "        features['hr_sd'] = np.nan\n",
    "        features['hr_brady_episodes'] = 0\n",
    "        features['hr_tachy_episodes'] = 0\n",
    "\n",
    "    # --- CLASSIFICATION LOGIC (Updated for correct metrics) ---\n",
    "    reasons = []\n",
    "    concern = \"green\"  # default\n",
    "\n",
    "    # PRIMARY RULE: Based on true ODI and prolonged hypoxemia\n",
    "    if features['odi'] >= 5.0 or features['percent_time_below_88'] > 5: # >5% time below 88% is severe\n",
    "        concern = \"red\"\n",
    "        reasons.append(f\"Oxygen Desaturation Index (ODI) ≥5.0 ({features['odi']}/hr) or significant time with SpO₂ <88%\")\n",
    "    \n",
    "    # SECONDARY RULE: Based on lower ODI or less severe hypoxemia\n",
    "    elif features['odi'] >= 3.0 or features['percent_time_below_90'] > 10:\n",
    "        concern = \"orange\"\n",
    "        reasons.append(f\"Moderate ODI ({features['odi']}/hr) or prolonged time with SpO₂ <90%\")\n",
    "    \n",
    "    # TERTIARY RULE: Mild indicators\n",
    "    elif features['odi'] > 0 or (features['nocturnal_drop'] is not np.nan and features['nocturnal_drop'] <= -2):\n",
    "        concern = \"yellow\"\n",
    "        reasons.append(\"Mild nocturnal desaturation detected\")\n",
    "\n",
    "    # MODIFIER RULE: HR Variability can upgrade concern one level (e.g., yellow to orange, orange to red)\n",
    "    # Check if HR variability is high, suggesting autonomic arousal\n",
    "    if features['hr_sd'] > 8.0 and concern != \"red\": \n",
    "        if concern == \"green\":\n",
    "            concern = \"yellow\"\n",
    "            reasons.append(\"Elevated nocturnal heart rate variability.\")\n",
    "        elif concern == \"yellow\":\n",
    "            concern = \"orange\"\n",
    "            reasons.append(\"Elevated nocturnal heart rate variability plus desaturation.\")\n",
    "        # if already orange, it stays orange (don't upgrade to red on HR alone)\n",
    "\n",
    "    return {\n",
    "        \"concern\": concern,\n",
    "        \"features\": features,\n",
    "        \"reasons\": reasons\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
