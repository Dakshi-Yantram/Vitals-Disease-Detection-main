{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7863d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc258136",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESH_SPO2_LOW = 92\n",
    "THRESH_SPO2_CRITICAL = 88\n",
    "THRESH_SHOCK_INDEX_WARNING = 0.9\n",
    "THRESH_SHOCK_INDEX_CRITICAL = 1.0\n",
    "THRESH_MAP_LOW = 65  # Mean Arterial Pressure threshold for shock\n",
    "THRESH_LACTATE_HIGH = 2.0  # mmol/L for tissue hypoperfusion\n",
    "THRESH_LACTATE_CRITICAL = 4.0\n",
    "THRESH_UO_LOW = 0.5  # mL/kg/hr (oliguria)\n",
    "\n",
    "# Trend Analysis\n",
    "TREND_WINDOW = 6  # Number of readings for short-term trend analysis\n",
    "\n",
    "\n",
    "# AGE-SPECIFIC VITAL SIGN THRESHOLDS (Low, Normal, High)\n",
    "\n",
    "AGE_THRESHOLDS = {\n",
    "    'neonate': {\n",
    "        'rr_low': 30, 'rr_normal': 40, 'rr_high': 60,\n",
    "        'hr_low': 100, 'hr_normal': 140, 'hr_high': 160,\n",
    "        'sbp_low': 60, 'sbp_normal': 70, 'sbp_high': 90,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.2, 'temp_high': 38.0\n",
    "    },\n",
    "    'infant': {\n",
    "        'rr_low': 24, 'rr_normal': 30, 'rr_high': 40,\n",
    "        'hr_low': 80, 'hr_normal': 120, 'hr_high': 140,\n",
    "        'sbp_low': 70, 'sbp_normal': 85, 'sbp_high': 100,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.2, 'temp_high': 38.0\n",
    "    },\n",
    "    'child': {\n",
    "        'rr_low': 16, 'rr_normal': 20, 'rr_high': 30,\n",
    "        'hr_low': 70, 'hr_normal': 90, 'hr_high': 110,\n",
    "        'sbp_low': 80, 'sbp_normal': 95, 'sbp_high': 110,\n",
    "        'temp_low': 36.0, 'temp_normal': 37.0, 'temp_high': 38.0\n",
    "    },\n",
    "    'adolescent': {\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 20,\n",
    "        'hr_low': 60, 'hr_normal': 75, 'hr_high': 100,\n",
    "        'sbp_low': 90, 'sbp_normal': 105, 'sbp_high': 120,\n",
    "        'temp_low': 35.8, 'temp_normal': 36.8, 'temp_high': 37.8\n",
    "    },\n",
    "    'adult': {\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 20,\n",
    "        'hr_low': 60, 'hr_normal': 80, 'hr_high': 100,\n",
    "        'sbp_low': 90, 'sbp_normal': 115, 'sbp_high': 130,\n",
    "        'temp_low': 35.5, 'temp_normal': 36.8, 'temp_high': 38.0\n",
    "    },\n",
    "    'geriatric': {  # Added for elderly patients who may have different baselines\n",
    "        'rr_low': 12, 'rr_normal': 16, 'rr_high': 24, # Often higher RR baseline\n",
    "        'hr_low': 55, 'hr_normal': 70, 'hr_high': 90, # Often lower HR\n",
    "        'sbp_low': 90, 'sbp_normal': 125, 'sbp_high': 140, # Often higher SBP\n",
    "        'temp_low': 35.5, 'temp_normal': 36.5, 'temp_high': 37.5 # Often lower temp\n",
    "    }\n",
    "}\n",
    "\n",
    "#--- HF-specific thresholds \n",
    "HF_RR_SLOPE_BPM_PER_HR = 1.0           # slope threshold (bpm / hour)\n",
    "HF_SPO2_BURDEN_PCT_24H = 0.30          # fraction of readings <92 in 24h to flag burden\n",
    "HF_SPO2_LOW = 92\n",
    "HF_SPO2_CRITICAL = 88\n",
    "HF_RR_TACHY = 20                       # absolute tachypnea threshold (bpm)\n",
    "HF_RR_EMERGENT = 30\n",
    "HF_SBP_HYPOTENSION = 90                # SBP < 90 urgent\n",
    "HF_SBP_RISE_SLOPE_24H = 5.0            # mmHg per 24h -> small positive weight\n",
    "HF_SLOPE_MIN_READINGS = 3              # min points to compute slope\n",
    "HF_SPO2_CRITICAL_SUSTAINED_MINUTES = 5 # sustained low SpO2 window for critical override\n",
    "\n",
    "# safety for shock index naming compatibility\n",
    "THRESH_SHOCK_INDEX_HIGH = THRESH_SHOCK_INDEX_CRITICAL if 'THRESH_SHOCK_INDEX_CRITICAL' in globals() else 1.0\n",
    "\n",
    "# Score weights (tunable)\n",
    "HF_SCORE_WEIGHTS = {\n",
    "    \"rr_slope\": 3,\n",
    "    \"rr_tachy\": 2,\n",
    "    \"spo2_burden\": 3,\n",
    "    \"spo2_critical_sustained\": 4,\n",
    "    \"sbp_hypotension\": 4,\n",
    "    \"sbp_rising_trend\": 2,\n",
    "    \"shock_index_critical\": 3,\n",
    "    \"rr_emergent_with_low_spo2\": 4\n",
    "}\n",
    "\n",
    "# Score bins -> action\n",
    "HF_SCORE_ACTIONS = [\n",
    "    (8, \"URGENT: high risk — immediate escalation / ED contact\"),\n",
    "    (5, \"High risk: clinician review same day\"),\n",
    "    (3, \"Early warning: contact HF clinic / consider diuretic review\"),\n",
    "    (0, \"Routine monitoring\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "891fedf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_age_category(df):\n",
    "    \"\"\"\n",
    "    Assigns an age category based on the 'age' column in the DataFrame.\n",
    "    Now includes more granular pediatric categories and a geriatric category.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    def _categorize(age):\n",
    "        if age <= 0.083: return 'neonate'     # < 1 month\n",
    "        elif age <= 1:   return 'infant'      # 1 month - 1 year\n",
    "        elif age < 5:    return 'child'       # 1 - 5 years\n",
    "        elif age < 13:   return 'adolescent'  # 5 - 12 years\n",
    "        elif age < 65:   return 'adult'       # 13 - 64 years\n",
    "        else:            return 'geriatric'   # 65+ years\n",
    "    \n",
    "    if 'age' in df.columns:\n",
    "        df['age_category'] = df['age'].apply(_categorize)\n",
    "    else:\n",
    "        # Default to adult if age is not provided\n",
    "        df['age_category'] = 'adult'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56dc56f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_vital_range_flags(df):\n",
    "    \"\"\"\n",
    "    Applies age-specific thresholds to flag abnormal vital signs.\n",
    "    Now includes flags for all parameters needed across pipelines.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = assign_age_category(df)  # Inject age group\n",
    "\n",
    "    # SpO₂ flags (Absolute threshold)\n",
    "    df['flag_spo2_low'] = df['spo2'] < THRESH_SPO2_LOW\n",
    "    df['flag_spo2_critical'] = df['spo2'] < THRESH_SPO2_CRITICAL\n",
    "\n",
    "    # Temperature flags\n",
    "    df['flag_temp_high'] = df.apply(lambda row: row['temperature'] >= AGE_THRESHOLDS[row['age_category']]['temp_high'], axis=1)\n",
    "    df['flag_temp_low'] = df.apply(lambda row: row['temperature'] < AGE_THRESHOLDS[row['age_category']]['temp_low'], axis=1)\n",
    "\n",
    "    # Respiratory Rate flags\n",
    "    df['flag_rr_low'] = df.apply(lambda row: row['resp_rate'] < AGE_THRESHOLDS[row['age_category']]['rr_low'], axis=1)\n",
    "    df['flag_rr_high'] = df.apply(lambda row: row['resp_rate'] >= AGE_THRESHOLDS[row['age_category']]['rr_high'], axis=1)\n",
    "\n",
    "    # Heart Rate flags\n",
    "    df['flag_hr_low'] = df.apply(lambda row: row['heart_rate'] < AGE_THRESHOLDS[row['age_category']]['hr_low'], axis=1)\n",
    "    df['flag_hr_high'] = df.apply(lambda row: row['heart_rate'] >= AGE_THRESHOLDS[row['age_category']]['hr_high'], axis=1)\n",
    "\n",
    "    # Calculate Shock Index (handle division by zero)\n",
    "    df['shock_index'] = df['heart_rate'] / np.clip(df['sbp'], a_min=1, a_max=None)    \n",
    "    # Flag based on Shock Index\n",
    "    df['flag_si_warning'] = df['shock_index'] >= THRESH_SHOCK_INDEX_WARNING\n",
    "    df['flag_si_critical'] = df['shock_index'] >= THRESH_SHOCK_INDEX_CRITICAL\n",
    "\n",
    "    # Blood Pressure flags\n",
    "    df['flag_sbp_low'] = df.apply(lambda row: row['sbp'] < AGE_THRESHOLDS[row['age_category']]['sbp_low'], axis=1)\n",
    "    df['flag_sbp_high'] = df.apply(lambda row: row['sbp'] >= AGE_THRESHOLDS[row['age_category']]['sbp_high'], axis=1)\n",
    "    df['flag_dbp_low'] = df.apply(lambda row: row['dbp'] < (AGE_THRESHOLDS[row['age_category']]['sbp_low'] * 0.6), axis=1) # Estimate DBP low\n",
    "    df['flag_dbp_high'] = df.apply(lambda row: row['dbp'] >= (AGE_THRESHOLDS[row['age_category']]['sbp_high'] * 0.6), axis=1) # Estimate DBP high\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e490fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recent_trends_delta(df):\n",
    "    \"\"\"\n",
    "    Computes recent trends for each vital by differencing consecutive readings.\n",
    "    Uses age-specific thresholds + detects likely false-positive variations\n",
    "    (e.g., transient spikes/drops or conflicting multi-vital patterns).\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    if 'age_category' not in df.columns:\n",
    "        df = assign_age_category(df)\n",
    "\n",
    "    trends = {}\n",
    "    recent = df.tail(TREND_WINDOW)\n",
    "    if recent.empty:\n",
    "        return trends\n",
    "\n",
    "    age_group = recent['age_category'].iloc[-1]\n",
    "    thresholds = AGE_THRESHOLDS[age_group]\n",
    "\n",
    "    vital_map = {\n",
    "        'rr': ('rr_low', 'rr_normal', 'rr_high'),\n",
    "        'hr': ('hr_low', 'hr_normal', 'hr_high'), \n",
    "        'sbp': ('sbp_low', 'sbp_normal', 'sbp_high'),\n",
    "        'temperature': ('temp_low', 'temp_normal', 'temp_high'),\n",
    "        'spo2': (None, None, None)\n",
    "    }\n",
    "\n",
    "    # --- Enhanced false positive detection ---\n",
    "    def is_transient_spike(values, delta, threshold_ratio=0.15):\n",
    "        \"\"\"Detect short-lived sharp deviations likely due to artifacts.\"\"\"\n",
    "        if len(values) < 3 or np.isnan(values).any():\n",
    "            return False\n",
    "        median_val = np.median(values)\n",
    "        if median_val == 0:\n",
    "            return False\n",
    "        deviation = abs(values[-1] - median_val)\n",
    "        return deviation / median_val > threshold_ratio and abs(delta) < 0.2 * deviation\n",
    "\n",
    "    def is_unstable_signal(values, threshold_ratio=0.5):\n",
    "        \"\"\"Detect excessive variability suggesting measurement noise.\"\"\"\n",
    "        if len(values) < 2 or np.isnan(values).any():\n",
    "            return False\n",
    "        value_std = np.std(values)\n",
    "        if value_std == 0:\n",
    "            return False\n",
    "        diff_std = np.std(np.diff(values))\n",
    "        return diff_std > threshold_ratio * value_std\n",
    "\n",
    "    for vital in ['rr', 'hr', 'sbp', 'temperature', 'spo2']:\n",
    "        if vital not in recent.columns or recent[vital].isnull().all():\n",
    "            continue\n",
    "\n",
    "        y = recent[vital].dropna().values\n",
    "        if len(y) < 2:\n",
    "            continue\n",
    "\n",
    "        avg_delta = np.mean(np.diff(y))\n",
    "        latest = y[-1]\n",
    "        trends[f\"{vital}_trend\"] = round(avg_delta, 3)\n",
    "\n",
    "        # --- Enhanced false positive detection ---\n",
    "        transient_spike = is_transient_spike(y, avg_delta)\n",
    "        unstable_signal = is_unstable_signal(y)\n",
    "        \n",
    "        fp_evidence = []\n",
    "        if transient_spike:\n",
    "            fp_evidence.append(\"transient_spike\")\n",
    "        if unstable_signal:\n",
    "            fp_evidence.append(\"unstable_signal\")\n",
    "\n",
    "        # SPO₂ special handling\n",
    "        if vital == 'spo2':\n",
    "            if latest < THRESH_SPO2_LOW:\n",
    "                if avg_delta > 0:\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                elif avg_delta < 0:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and flat\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        else:\n",
    "            low_key, norm_key, high_key = vital_map[vital]\n",
    "            low = thresholds[low_key]\n",
    "            normal = thresholds[norm_key]  \n",
    "            high = thresholds[high_key]\n",
    "\n",
    "            if latest < low or latest > high:\n",
    "                if (latest > high and avg_delta < 0) or (latest < low and avg_delta > 0):\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        if fp_evidence:\n",
    "            flag += f\" (possible false-positive: {', '.join(fp_evidence)})\"\n",
    "            trends[f\"{vital}_false_positive\"] = True\n",
    "            trends[f\"{vital}_fp_evidence\"] = fp_evidence\n",
    "            trends[f\"{vital}_confidence\"] = \"LOW\"\n",
    "        else:\n",
    "            trends[f\"{vital}_false_positive\"] = False\n",
    "            trends[f\"{vital}_confidence\"] = \"HIGH\"\n",
    "\n",
    "        trends[f\"{vital}_trend_flag\"] = flag\n",
    "\n",
    "    # --- Shock Index trend ---\n",
    "    if all(col in recent.columns for col in ['hr', 'sbp']):\n",
    "        hr = recent['hr'].values\n",
    "        sbp = np.clip(recent['sbp'].values, a_min=1, a_max=None)\n",
    "        si = hr / sbp\n",
    "\n",
    "        if len(si) >= 2:\n",
    "            avg_si_delta = np.mean(np.diff(si))\n",
    "            trends['shock_index_trend'] = round(avg_si_delta, 3)\n",
    "\n",
    "            latest_si = si[-1]\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_CRITICAL:\n",
    "                flag = \"Shock Index high — improving\" if avg_si_delta < 0 else \"Shock Index high — worsening\"\n",
    "            else:\n",
    "                flag = \"Normal but improving\" if avg_si_delta < 0 else \"Normal but rising\"\n",
    "\n",
    "            si_fp_evidence = []\n",
    "            if is_unstable_signal(si, threshold_ratio=0.3):\n",
    "                si_fp_evidence.append(\"unstable_si\")\n",
    "\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_CRITICAL:\n",
    "                latest_hr = recent['hr'].iloc[-1]\n",
    "                latest_sbp = recent['sbp'].iloc[-1]\n",
    "                hr_normal = latest_hr < thresholds['hr_high']\n",
    "                sbp_normal = latest_sbp >= thresholds['sbp_low']\n",
    "                \n",
    "                if (hr_normal and not sbp_normal) or (sbp_normal and not hr_normal):\n",
    "                    si_fp_evidence.append(\"single_component_abnormality\")\n",
    "\n",
    "            if si_fp_evidence:\n",
    "                flag += f\" (possible false-positive: {', '.join(si_fp_evidence)})\"\n",
    "                trends['shock_index_false_positive'] = True\n",
    "                trends['shock_index_fp_evidence'] = si_fp_evidence\n",
    "                trends['shock_index_confidence'] = \"LOW\"\n",
    "            else:\n",
    "                trends['shock_index_false_positive'] = False  \n",
    "                trends['shock_index_confidence'] = \"HIGH\"\n",
    "\n",
    "            trends['shock_index_trend_flag'] = flag\n",
    "\n",
    "    # --- Overall confidence summary ---\n",
    "    false_positive_count = sum(1 for key in trends if key.endswith('_false_positive') and trends[key])\n",
    "    total_metrics = sum(1 for key in trends if key.endswith('_false_positive'))\n",
    "    \n",
    "    if total_metrics > 0:\n",
    "        fp_ratio = false_positive_count / total_metrics\n",
    "        if fp_ratio >= 0.5:\n",
    "            trends['overall_confidence'] = \"LOW\"\n",
    "        elif fp_ratio >= 0.25:\n",
    "            trends['overall_confidence'] = \"MEDIUM\" \n",
    "        else:\n",
    "            trends['overall_confidence'] = \"HIGH\"\n",
    "    else:\n",
    "        trends['overall_confidence'] = \"HIGH\"\n",
    "\n",
    "    return trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b043c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ensure_sorted_index(df):\n",
    "    df = df.copy()\n",
    "    if 'timestamp' not in df.columns:\n",
    "        raise ValueError(\"DataFrame must contain 'timestamp' column.\")\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    return df.sort_values('timestamp').reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "022c5f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_time_slope(series_vals, series_times):\n",
    "    \"\"\"\n",
    "    Compute slope per hour using linear fit (units = value per hour).\n",
    "    series_times: pandas Series of timestamps\n",
    "    series_vals: numpy array or Series of numeric values\n",
    "    Returns slope (float) in units per hour. If not computable, returns np.nan.\n",
    "    \"\"\"\n",
    "    if len(series_vals) < HF_SLOPE_MIN_READINGS:\n",
    "        return np.nan\n",
    "    \n",
    "    # Convert to numpy arrays to avoid pandas index issues\n",
    "    series_vals_np = np.array(series_vals, dtype=float)\n",
    "    \n",
    "    # Convert timestamps to hours relative to first time\n",
    "    # FIX: Use .values to get numpy array and avoid index issues\n",
    "    series_times_np = pd.to_datetime(series_times).values\n",
    "    t_seconds = series_times_np.astype('int64') // 1_000_000_000  # Convert to seconds since epoch\n",
    "    \n",
    "    # If all times identical, avoid polyfit error\n",
    "    if np.all(t_seconds == t_seconds[0]):\n",
    "        return np.nan\n",
    "    \n",
    "    try:\n",
    "        t_hours = (t_seconds - t_seconds[0]) / 3600.0\n",
    "        slope, intercept = np.polyfit(t_hours, series_vals_np, 1)\n",
    "        return float(slope)  # units per hour\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def _percent_below(series, threshold):\n",
    "    arr = series.dropna().values\n",
    "    if len(arr) == 0:\n",
    "        return 0.0\n",
    "    return float((arr < threshold).sum()) / float(len(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52273825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sustained_low_event(series_spo2, series_times, thresh, min_minutes):\n",
    "    \"\"\"\n",
    "    Check if there exists any sustained interval where SpO2 <= thresh\n",
    "    for at least min_minutes. series_times should be pandas timestamps aligned with series_spo2.\n",
    "    \"\"\"\n",
    "    if len(series_spo2) == 0:\n",
    "        return False\n",
    "    df = pd.DataFrame({\"spo2\": series_spo2.values, \"timestamp\": pd.to_datetime(series_times.values)})\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['is_low'] = df['spo2'] <= thresh\n",
    "    if not df['is_low'].any():\n",
    "        return False\n",
    "\n",
    "    # group consecutive low readings\n",
    "    groups = (df['is_low'] != df['is_low'].shift()).cumsum()\n",
    "    grouped = df.groupby(groups)\n",
    "    for _, g in grouped:\n",
    "        if not g['is_low'].iloc[0]:\n",
    "            continue\n",
    "        duration = g['timestamp'].iloc[-1] - g['timestamp'].iloc[0]\n",
    "        if duration >= timedelta(minutes=min_minutes):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b763674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_decompensation_assessment(df_patient, window_hours=24):\n",
    "    \"\"\"\n",
    "    Assess HF decompensation using only continuous vital signs.\n",
    "    No weight data required.\n",
    "    \"\"\"\n",
    "    df = _ensure_sorted_index(df_patient)\n",
    "    now = df['timestamp'].iloc[-1]\n",
    "\n",
    "    # subset window\n",
    "    window_start = now - pd.Timedelta(hours=window_hours)\n",
    "    window_df = df[df['timestamp'] >= window_start].copy()\n",
    "    if window_df.empty:\n",
    "        raise ValueError(\"No data in the lookback window to compute HF assessment.\")\n",
    "\n",
    "    # ensure age_category exists\n",
    "    if 'age_category' not in df.columns:\n",
    "        try:\n",
    "            df = assign_age_category(df)\n",
    "            window_df = df[df['timestamp'] >= window_start]\n",
    "        except Exception:\n",
    "            df['age_category'] = 'adult'\n",
    "            window_df['age_category'] = 'adult'\n",
    "\n",
    "    flags = {}\n",
    "    trends = {}\n",
    "\n",
    "    # ---- SpO2 burden & critical sustained ----\n",
    "    spo2_series = window_df['spo2'].dropna()\n",
    "    trends['spo2_burden92_frac_24h'] = _percent_below(spo2_series, HF_SPO2_LOW)\n",
    "    flags['spo2_burden'] = trends['spo2_burden92_frac_24h'] >= HF_SPO2_BURDEN_PCT_24H\n",
    "    flags['spo2_critical_sustained'] = _sustained_low_event(window_df['spo2'], window_df['timestamp'],\n",
    "                                                             HF_SPO2_CRITICAL, HF_SPO2_CRITICAL_SUSTAINED_MINUTES)\n",
    "\n",
    "    # ---- RR mean and slope ----\n",
    "    rr_series = window_df['resp_rate'].dropna()\n",
    "    trends['rr_mean_24h'] = float(rr_series.mean()) if len(rr_series) > 0 else np.nan\n",
    "    trends['rr_slope_bph'] = _compute_time_slope(rr_series.values, window_df.loc[rr_series.index, 'timestamp'])\n",
    "    flags['rr_slope'] = not np.isnan(trends['rr_slope_bph']) and trends['rr_slope_bph'] >= HF_RR_SLOPE_BPM_PER_HR\n",
    "    flags['rr_tachy'] = (trends.get('rr_mean_24h', 0) >= HF_RR_TACHY)\n",
    "\n",
    "    # ---- SBP mean and slope ----\n",
    "    sbp_series = window_df['sbp'].dropna()\n",
    "    trends['sbp_mean_24h'] = float(sbp_series.mean()) if len(sbp_series) > 0 else np.nan\n",
    "    trends['sbp_slope_mmh_per_hr'] = _compute_time_slope(sbp_series.values, window_df.loc[sbp_series.index, 'timestamp'])\n",
    "    flags['sbp_rising_trend'] = False\n",
    "    if not np.isnan(trends['sbp_slope_mmh_per_hr']):\n",
    "        sbp_slope_per_24h = trends['sbp_slope_mmh_per_hr'] * 24.0\n",
    "        trends['sbp_slope_mmh_per_24h'] = float(round(sbp_slope_per_24h, 3))\n",
    "        flags['sbp_rising_trend'] = sbp_slope_per_24h >= HF_SBP_RISE_SLOPE_24H\n",
    "\n",
    "    # ---- Hypotension safety override ----\n",
    "    recent_6h = df[df['timestamp'] >= now - pd.Timedelta(hours=6)]\n",
    "    flags['sbp_hypotension'] = False\n",
    "    if 'sbp' in recent_6h.columns and not recent_6h['sbp'].dropna().empty:\n",
    "        flags['sbp_hypotension'] = recent_6h['sbp'].min() < HF_SBP_HYPOTENSION\n",
    "\n",
    "    # ---- Shock Index critical check ----\n",
    "    flags['shock_index_critical'] = False\n",
    "    if 'shock_index' in window_df.columns:\n",
    "        if window_df['shock_index'].dropna().max() >= THRESH_SHOCK_INDEX_HIGH:\n",
    "            flags['shock_index_critical'] = True\n",
    "    else:\n",
    "        if all(col in window_df.columns for col in ['heart_rate', 'sbp']):\n",
    "            hr_values = window_df['heart_rate'].dropna().values\n",
    "            sbp_values = window_df['sbp'].dropna().values\n",
    "            min_len = min(len(hr_values), len(sbp_values))\n",
    "            if min_len > 0:\n",
    "                hr_values = hr_values[:min_len]\n",
    "                sbp_values = sbp_values[:min_len]\n",
    "                si_vals = hr_values / np.clip(sbp_values, 1, None)\n",
    "                if si_vals.max() >= THRESH_SHOCK_INDEX_HIGH:\n",
    "                    flags['shock_index_critical'] = True\n",
    "\n",
    "    # ---- Safety overrides: emergent RR + low SpO2 combo ----\n",
    "    flags['rr_emergent_with_low_spo2'] = False\n",
    "    rr_clean = df['resp_rate'].dropna().reset_index(drop=True) if 'resp_rate' in df.columns else pd.Series()\n",
    "    spo2_clean = df['spo2'].dropna().reset_index(drop=True) if 'spo2' in df.columns else pd.Series()\n",
    "    \n",
    "    if not rr_clean.empty and not spo2_clean.empty:\n",
    "        recent_rr_now = rr_clean.iloc[-1]\n",
    "        recent_spo2_now = spo2_clean.iloc[-1]\n",
    "        flags['rr_emergent_with_low_spo2'] = (recent_rr_now >= HF_RR_EMERGENT) and (recent_spo2_now < HF_SPO2_LOW)\n",
    "\n",
    "    # ---- Compose score ----\n",
    "    score = 0\n",
    "    for k, wt in HF_SCORE_WEIGHTS.items():\n",
    "        if flags.get(k, False):\n",
    "            score += wt\n",
    "\n",
    "    # ---- Map score to action ----\n",
    "    action = None\n",
    "    for thresh, act in HF_SCORE_ACTIONS:\n",
    "        if score >= thresh:\n",
    "            action = act\n",
    "            break\n",
    "    if action is None:\n",
    "        action = HF_SCORE_ACTIONS[-1][1]\n",
    "\n",
    "    # Safety override bump\n",
    "    if flags.get('spo2_critical_sustained') or flags.get('sbp_hypotension') or flags.get('rr_emergent_with_low_spo2'):\n",
    "        action = \"URGENT: immediate escalation / ED contact\"\n",
    "        score = max(score, 8)  # Ensure urgent threshold\n",
    "\n",
    "    # ---- Build summary ----\n",
    "    summary_parts = []\n",
    "    if flags.get('rr_slope'): summary_parts.append(f\"RR slope {round(trends.get('rr_slope_bph',0),3)} bpm/hr\")\n",
    "    if flags.get('rr_tachy'): summary_parts.append(f\"RR {trends.get('rr_mean_24h', '?')} bpm\")\n",
    "    if flags.get('spo2_burden'): summary_parts.append(f\"SpO2 <{HF_SPO2_LOW} for {int(trends['spo2_burden92_frac_24h']*100)}% (24h)\")\n",
    "    if flags.get('sbp_rising_trend'): summary_parts.append(f\"SBP rising {trends.get('sbp_slope_mmh_per_24h', '?')} mmHg/24h\")\n",
    "    if flags.get('spo2_critical_sustained'): summary_parts.append(f\"SpO2 ≤ {HF_SPO2_CRITICAL} sustained\")\n",
    "    if flags.get('sbp_hypotension'): summary_parts.append(\"Recent SBP < 90 mmHg\")\n",
    "    if flags.get('shock_index_critical'): summary_parts.append(\"Elevated shock index\")\n",
    "\n",
    "    summary = \" ; \".join(summary_parts) if summary_parts else \"No HF decompensation signals in window.\"\n",
    "\n",
    "    return {\n",
    "        \"flags\": flags,\n",
    "        \"trends\": trends,\n",
    "        \"score\": int(score),\n",
    "        \"action\": action,\n",
    "        \"summary\": summary\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e84de10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk Score: 11\n",
      "Alert Level: URGENT: immediate escalation / ED contact\n",
      "Summary: RR 29.24 bpm ; SpO2 <92 for 52% (24h) ; SBP rising 24.0 mmHg/24h ; SpO2 ≤ 88 sustained\n",
      "\n",
      "TRENDS\n",
      "spo2_burden92_frac_24h: 0.52\n",
      "rr_mean_24h: 29.24\n",
      "rr_slope_bph: 0.4999999999999997\n",
      "sbp_mean_24h: 141.0\n",
      "sbp_slope_mmh_per_hr: 1.0000000000000004\n",
      "sbp_slope_mmh_per_24h: 24.0\n",
      "\n",
      "FLAGS\n",
      "spo2_burden: True\n",
      "spo2_critical_sustained: True\n",
      "rr_tachy: True\n",
      "sbp_rising_trend: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Create a timestamp index for the last 36 hours\n",
    "now = datetime.now()\n",
    "timestamps = [now - timedelta(hours=h) for h in range(36, 0, -1)]  # 36 hours of data, most recent last\n",
    "\n",
    "# Create sample data for a decompensating patient\n",
    "sample_data = {\n",
    "    'timestamp': timestamps,\n",
    "    'spo2': [96, 95, 95, 94, 94, 93, 93, 92, 92, 91, 91, 90,  # First 12 hrs: slowly dropping\n",
    "             90, 90, 89, 89, 89, 88, 88, 88, 87, 87, 87, 86,  # Next 12 hrs: getting worse\n",
    "             98, 98, 100, 99, 100, 98, 100, 99, 100, 100, 99, 98], # Last 12 hrs: critical\n",
    "    'resp_rate': [18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,  # RR steadily increasing\n",
    "                  24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29,\n",
    "                  30, 30, 31, 31, 32, 32, 33, 33, 34, 34, 35, 35],\n",
    "    'heart_rate': [72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,  # HR increasing with RR\n",
    "                   84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95,\n",
    "                   96, 97, 100, 110, 100, 101, 102, 103, 104, 105, 106, 107],\n",
    "    'sbp': [118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,  # SBP slowly rising\n",
    "            130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141,\n",
    "            142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153],\n",
    "    'dbp': [72, 72, 73, 73, 74, 74, 75, 75, 76, 76, 77, 77,  # DBP also rising\n",
    "            78, 78, 79, 79, 80, 80, 81, 81, 82, 82, 83, 83,\n",
    "            84, 84, 85, 85, 86, 86, 87, 87, 88, 88, 89, 89],\n",
    "    'temperature': [36.8] * 36,  # Normal temp\n",
    "    'weight_kg': [80.0, 80.1, 80.3, 80.4, 80.6, 80.7, 80.9, 81.0, 81.2, 81.3, 81.5, 81.6,  # Weight gain >2kg/24h\n",
    "                  81.8, 81.9, 82.1, 82.2, 82.4, 82.5, 82.7, 82.8, 83.0, 83.1, 83.3, 83.4,\n",
    "                  83.6, 83.7, 83.9, 84.0, 84.2, 84.3, 84.5, 86, 86, 85, 85.2, 86.1],\n",
    "    'age': [67] * 36  # Geriatric patient\n",
    "} \n",
    "\n",
    "# Create the DataFrame (same as before, but we won't use weight)\n",
    "df_patient = pd.DataFrame(sample_data)\n",
    "\n",
    "# Run your HF assessment function (NO weight_col parameter)\n",
    "result = hf_decompensation_assessment(df_patient, window_hours=24)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Risk Score: {result['score']}\")\n",
    "print(f\"Alert Level: {result['action']}\")\n",
    "print(f\"Summary: {result['summary']}\")\n",
    "\n",
    "print(\"\\nTRENDS\")\n",
    "for key, value in result['trends'].items():\n",
    "    if value is not None and not key.startswith('weight'):  # Skip weight trends\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"\\nFLAGS\")\n",
    "for key, value in result['flags'].items():\n",
    "    if value and not key.startswith('weight'):  # Skip weight flags\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f711b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'flags': {'spo2_burden': True, 'spo2_critical_sustained': True, 'rr_slope': False, 'rr_tachy': True, 'sbp_rising_trend': True, 'sbp_hypotension': np.False_, 'shock_index_critical': False, 'rr_emergent_with_low_spo2': np.False_}, 'trends': {'spo2_burden92_frac_24h': 0.52, 'rr_mean_24h': 29.24, 'rr_slope_bph': 0.4999999999999997, 'sbp_mean_24h': 141.0, 'sbp_slope_mmh_per_hr': 1.0000000000000004, 'sbp_slope_mmh_per_24h': 24.0}, 'score': 11, 'action': 'URGENT: immediate escalation / ED contact', 'summary': 'RR 29.24 bpm ; SpO2 <92 for 52% (24h) ; SBP rising 24.0 mmHg/24h ; SpO2 ≤ 88 sustained'}\n"
     ]
    }
   ],
   "source": [
    "result = hf_decompensation_assessment(df_patient)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa864b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recent_trends_delta(df):\n",
    "    \"\"\"\n",
    "    Computes trends for each vital by differencing consecutive readings.\n",
    "    Applies stricter interpretation using age-specific thresholds.\n",
    "    \"\"\"\n",
    "    df = df.copy().sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "    if 'age_category' not in df.columns:\n",
    "        df = assign_age_category(df)\n",
    "\n",
    "    trends = {}\n",
    "    recent = df.tail(TREND_WINDOW)\n",
    "    age_group = recent['age_category'].iloc[-1]\n",
    "    thresholds = AGE_THRESHOLDS[age_group]\n",
    "\n",
    "    vital_map = {\n",
    "        'resp_rate': ('rr_low', 'rr_normal', 'rr_high'),\n",
    "        'heart_rate': ('hr_low', 'hr_normal', 'hr_high'),\n",
    "        'sbp': ('sbp_low', 'sbp_normal', 'sbp_high'),\n",
    "        'temperature': ('temp_low', 'temp_normal', 'temp_high'),\n",
    "        'spo2': (None, None, None)  # handled separately\n",
    "    }\n",
    "\n",
    "    for vital in ['resp_rate', 'heart_rate', 'sbp', 'temperature', 'spo2']:\n",
    "        if vital not in recent.columns or recent[vital].isnull().all():\n",
    "            continue\n",
    "\n",
    "        y = recent[vital].dropna().values\n",
    "        if len(y) < 2:\n",
    "            continue\n",
    "\n",
    "        avg_delta = np.mean(np.diff(y))\n",
    "        latest = y[-1]\n",
    "        trends[f\"{vital}_trend\"] = round(avg_delta, 3)\n",
    "\n",
    "        if vital == 'spo2':\n",
    "            if latest < THRESH_SPO2_LOW:\n",
    "                if avg_delta > 0:\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                elif avg_delta < 0:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and flat\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        else:\n",
    "            low_key, norm_key, high_key = vital_map[vital]\n",
    "            low = thresholds[low_key]\n",
    "            normal = thresholds[norm_key]\n",
    "            high = thresholds[high_key]\n",
    "\n",
    "            if latest < low or latest > high:\n",
    "                if (latest > high and avg_delta < 0) or (latest < low and avg_delta > 0):\n",
    "                    flag = \"Still abnormal — but improving\"\n",
    "                else:\n",
    "                    flag = \"Abnormal and worsening\"\n",
    "            else:\n",
    "                if avg_delta < 0:\n",
    "                    flag = \"Normal but deteriorating\"\n",
    "                else:\n",
    "                    flag = \"Normal and stable\"\n",
    "\n",
    "        trends[f\"{vital}_trend_flag\"] = flag\n",
    "\n",
    "    # Shock Index trend\n",
    "    if all(col in recent.columns for col in ['heart_rate', 'sbp']):\n",
    "        hr = recent['heart_rate'].values\n",
    "        sbp = np.clip(recent['sbp'].values, a_min=1, a_max=None)\n",
    "        si = hr / sbp\n",
    "\n",
    "        if len(si) >= 2:\n",
    "            avg_si_delta = np.mean(np.diff(si))\n",
    "            trends['shock_index_trend'] = round(avg_si_delta, 3)\n",
    "\n",
    "            latest_si = si[-1]\n",
    "            if latest_si >= THRESH_SHOCK_INDEX_HIGH:\n",
    "                flag = \"Shock Index high — improving\" if avg_si_delta < 0 else \"Shock Index high — worsening\"\n",
    "            else:\n",
    "                flag = \"Normal but improving\" if avg_si_delta < 0 else \"Normal but rising\"\n",
    "\n",
    "            trends['shock_index_trend_flag'] = flag\n",
    "\n",
    "    return trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dfa171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main HF pipeline function\n",
    "def hf_decompensation_assessment(df_patient,\n",
    "                                 window_hours=24,\n",
    "                                 weight_col='weight_kg'):\n",
    "    \"\"\"\n",
    "    Assess HF decompensation for a single patient's timeseries DataFrame.\n",
    "    \"\"\"\n",
    "    df = _ensure_sorted_index(df_patient)\n",
    "    now = df['timestamp'].iloc[-1]\n",
    "\n",
    "    # subset window\n",
    "    window_start = now - pd.Timedelta(hours=window_hours)\n",
    "    window_df = df[df['timestamp'] >= window_start].copy()\n",
    "    if window_df.empty:\n",
    "        raise ValueError(\"No data in the lookback window to compute HF assessment.\")\n",
    "\n",
    "    # ensure age_category exists\n",
    "    if 'age_category' not in df.columns:\n",
    "        try:\n",
    "            df = assign_age_category(df)\n",
    "            window_df = df[df['timestamp'] >= window_start]\n",
    "        except Exception:\n",
    "            df['age_category'] = 'adult'\n",
    "            window_df['age_category'] = 'adult'\n",
    "\n",
    "    flags = {}\n",
    "    trends = {}\n",
    "\n",
    "    # Weight gain 24h\n",
    "    flags['weight_gain_24h'] = False\n",
    "    if weight_col in df.columns:\n",
    "        # FIX: Reset index to avoid KeyError\n",
    "        weight_data = df.dropna(subset=[weight_col]).reset_index(drop=True)\n",
    "        if not weight_data.empty:\n",
    "            latest_weight = weight_data.iloc[-1][weight_col]  # Get last weight\n",
    "            # find weight at (now - 24h) as nearest earlier measurement\n",
    "            t24 = now - pd.Timedelta(hours=24)\n",
    "            earlier = df[df['timestamp'] <= t24].dropna(subset=[weight_col])\n",
    "            if not earlier.empty:\n",
    "                # Reset index to avoid KeyError\n",
    "                earlier = earlier.reset_index(drop=True)\n",
    "                weight_24h = earlier.iloc[-1][weight_col]\n",
    "                delta_w = latest_weight - weight_24h\n",
    "                trends['weight_delta_24h_kg'] = float(round(delta_w, 3))\n",
    "                flags['weight_gain_24h'] = trends['weight_delta_24h_kg'] >= HF_WEIGHT_GAIN_KG_24H\n",
    "\n",
    "    # SpO2 burden & critical sustained\n",
    "    spo2_series = window_df['spo2'].dropna()\n",
    "    trends['spo2_burden92_frac_24h'] = _percent_below(spo2_series, HF_SPO2_LOW)\n",
    "    flags['spo2_burden'] = trends['spo2_burden92_frac_24h'] >= HF_SPO2_BURDEN_PCT_24H\n",
    "    flags['spo2_critical_sustained'] = _sustained_low_event(window_df['spo2'], window_df['timestamp'],\n",
    "                                                             HF_SPO2_CRITICAL, HF_SPO2_CRITICAL_SUSTAINED_MINUTES)\n",
    "\n",
    "    # RR mean and slope\n",
    "    rr_series = window_df['resp_rate'].dropna()\n",
    "    trends['rr_mean_24h'] = float(rr_series.mean()) if len(rr_series) > 0 else np.nan\n",
    "    trends['rr_slope_bph'] = _compute_time_slope(rr_series.values, window_df.loc[rr_series.index, 'timestamp'])\n",
    "    flags['rr_slope'] = not np.isnan(trends['rr_slope_bph']) and trends['rr_slope_bph'] >= HF_RR_SLOPE_BPM_PER_HR\n",
    "    flags['rr_tachy'] = (trends.get('rr_mean_24h', 0) >= HF_RR_TACHY)\n",
    "\n",
    "    # SBP mean and slope\n",
    "    sbp_series = window_df['sbp'].dropna()\n",
    "    trends['sbp_mean_24h'] = float(sbp_series.mean()) if len(sbp_series) > 0 else np.nan\n",
    "    trends['sbp_slope_mmh_per_hr'] = _compute_time_slope(sbp_series.values, window_df.loc[sbp_series.index, 'timestamp'])\n",
    "    flags['sbp_rising_trend'] = False\n",
    "    if not np.isnan(trends['sbp_slope_mmh_per_hr']):\n",
    "        sbp_slope_per_24h = trends['sbp_slope_mmh_per_hr'] * 24.0\n",
    "        trends['sbp_slope_mmh_per_24h'] = float(round(sbp_slope_per_24h, 3))\n",
    "        flags['sbp_rising_trend'] = sbp_slope_per_24h >= HF_SBP_RISE_SLOPE_24H\n",
    "\n",
    "    # hypotension safety override\n",
    "    recent_6h = df[df['timestamp'] >= now - pd.Timedelta(hours=6)]\n",
    "    flags['sbp_hypotension'] = False\n",
    "    if 'sbp' in recent_6h.columns and not recent_6h['sbp'].dropna().empty:\n",
    "        flags['sbp_hypotension'] = recent_6h['sbp'].min() < HF_SBP_HYPOTENSION\n",
    "\n",
    "    # Shock Index critical check\n",
    "    flags['shock_index_critical'] = False\n",
    "    if 'shock_index' in window_df.columns:\n",
    "        if window_df['shock_index'].dropna().max() >= THRESH_SHOCK_INDEX_HIGH:\n",
    "            flags['shock_index_critical'] = True\n",
    "    else:\n",
    "        if all(col in window_df.columns for col in ['heart_rate', 'sbp']):\n",
    "            # FIX: Use .values directly from the Series to avoid index issues\n",
    "            hr_values = window_df['heart_rate'].dropna().values\n",
    "            sbp_values = window_df['sbp'].dropna().values\n",
    "            # Use the shorter length to align arrays\n",
    "            min_len = min(len(hr_values), len(sbp_values))\n",
    "            if min_len > 0:\n",
    "                hr_values = hr_values[:min_len]\n",
    "                sbp_values = sbp_values[:min_len]\n",
    "                si_vals = hr_values / np.clip(sbp_values, 1, None)\n",
    "                if si_vals.max() >= THRESH_SHOCK_INDEX_HIGH:\n",
    "                    flags['shock_index_critical'] = True\n",
    "\n",
    "    # Safety overrides: emergent RR + low SpO2 combo\n",
    "    flags['rr_emergent_with_low_spo2'] = False\n",
    "    # FIX: Reset index before using iloc\n",
    "    rr_clean = df['resp_rate'].dropna().reset_index(drop=True) if 'resp_rate' in df.columns else pd.Series()\n",
    "    spo2_clean = df['spo2'].dropna().reset_index(drop=True) if 'spo2' in df.columns else pd.Series()\n",
    "    \n",
    "    if not rr_clean.empty and not spo2_clean.empty:\n",
    "        recent_rr_now = rr_clean.iloc[-1]\n",
    "        recent_spo2_now = spo2_clean.iloc[-1]\n",
    "        flags['rr_emergent_with_low_spo2'] = (recent_rr_now >= HF_RR_EMERGENT) and (recent_spo2_now < HF_SPO2_LOW)\n",
    "\n",
    "    # Compose score\n",
    "    score = 0\n",
    "    for k, wt in HF_SCORE_WEIGHTS.items():\n",
    "        if flags.get(k, False):\n",
    "            score += wt\n",
    "\n",
    "    # Map score to action\n",
    "    action = None\n",
    "    for thresh, act in HF_SCORE_ACTIONS:\n",
    "        if score >= thresh:\n",
    "            action = act\n",
    "            break\n",
    "    if action is None:\n",
    "        action = HF_SCORE_ACTIONS[-1][1]\n",
    "\n",
    "    # Safety override bump\n",
    "    if flags.get('spo2_critical_sustained') or flags.get('sbp_hypotension') or flags.get('rr_emergent_with_low_spo2'):\n",
    "        action = \"URGENT: immediate escalation / ED contact\"\n",
    "        score = max(score, HF_SCORE_WEIGHTS.get('spo2_critical_sustained', 4))\n",
    "\n",
    "    # Build short summary\n",
    "    summary_parts = []\n",
    "    if flags.get('weight_gain_24h'): summary_parts.append(f\"Weight +{trends.get('weight_delta_24h_kg','?')} kg (24h)\")\n",
    "    if flags.get('rr_slope'): summary_parts.append(f\"RR slope {round(trends.get('rr_slope_bph',0),3)} bpm/hr\")\n",
    "    if flags.get('spo2_burden'): summary_parts.append(f\"SpO2 <{HF_SPO2_LOW} for {int(trends['spo2_burden92_frac_24h']*100)}% (24h)\")\n",
    "    if flags.get('sbp_rising_trend'): summary_parts.append(f\"SBP rising {trends.get('sbp_slope_mmh_per_24h', '?')} mmHg/24h\")\n",
    "    if flags.get('spo2_critical_sustained'): summary_parts.append(f\"SpO2 ≤ {HF_SPO2_CRITICAL} sustained\")\n",
    "    if flags.get('sbp_hypotension'): summary_parts.append(\"Recent SBP < 90 mmHg\")\n",
    "\n",
    "    summary = \" ; \".join(summary_parts) if summary_parts else \"No HF decompensation signals in window.\"\n",
    "\n",
    "    return {\n",
    "        \"flags\": flags,\n",
    "        \"trends\": trends,\n",
    "        \"score\": int(score),\n",
    "        \"action\": action,\n",
    "        \"summary\": summary\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
